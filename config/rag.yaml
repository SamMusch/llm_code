# config/rag.yaml
# Purpose:
  # gives full declarative control outside Python code
  # makes your pipeline reproducible
  # required for LRAT-style features, multi-environment runs, or toggling paths/settings without editing code.

rag:
  paths:
    data_dir: "Data"
    docs_dir: "Data/docs"
    index_dir: "Data/index"
    logs_dir: "Data/logs"

  llm:
    provider: "ollama" 
    model: "qwen2.5:3b" #  "llama3.2:1b"
    base_url: "http://host.docker.internal:11434" # macOS host Ollama (Metal). For Docker-to-Docker, use http://ollama:11434

  embedding:
    model: "mxbai-embed-large" # "nomic-embed-text" #"text-embedding-3-small"
    chunk_size: 1200
    chunk_overlap: 200
    top_k: 4

  runtime:
    max_retries: 3
    hallucination_guard: true
    max_context_chars: 60000

  postgres:
    uri: null
    # Restrict visibility to this schema (DB-level enforcement already applied)
    schema: "llm_code"